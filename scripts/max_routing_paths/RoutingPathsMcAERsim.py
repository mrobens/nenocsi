#!/usr/bin/env python3
#------------------------------------------------------------------------
#
# McAERsim-Framework: Network traffic within McAERsim generated by NEST
# Copyright (C) 2024 Forschungszentrum Juelich GmbH, ZEA-2
# Author: Markus Robens <https://www.fz-juelich.de/profile/robens_m>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the license, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
#------------------------------------------------------------------------
#
# This Python script generates histogram data on maximum routing paths
# lengths for multicast routing and the topology passed as parameter
# based on the files used for data exchange between NEST and McAERsim.
# Examples are contained in the NoC-Sim-Input subfolder of the dataset
# available at https://doi.org/10.5281/zenodo.10159252.
#
# The script needs to receive five parameters: the path to the
# connectivity file and the spike-recorder files used for data exchange
# and generated by NEST, the topology, the number of neurons mapped to
# a node, the size of the network in x direction, and the size of the
# network in y direction.
#
#------------------------------------------------------------------------
import sys
import os
import numpy as np
import yaml
from collections import defaultdict
from helpers import __gather_metadata, __load_spike_times
from helpers_aux import __get_node_ID_4_neuron

if( len( sys.argv ) != 6):
    print("""Usage: ./RoutingPathsMcAERsim <path> <topo> <npns> <dimx> <dimy>
where <path> is the path to the YAML file generated by NEST,
      <topo> is the topology (mesh or torus)
      <npns> is the number of neurons per processing element,
      <dimx> is the size of the network in x direction,
      <dimy> is the size of the network in y direction.""")
    sys.exit(0)
else:
    pname = sys.argv[1]
    topo = sys.argv[2]
    npCU = sys.argv[3]
    dimx = sys.argv[4]
    dimy = sys.argv[5]
    if (not pname.startswith('/')):
        print('Please provide an absolute path to the YAML file generated by NEST as first argument.')
        sys.exit(0)
    if (not (topo.isalpha() and ((topo.lower() == "mesh") or (topo.lower() == "torus")))):
        print('Please select a proper topology as second argument: mesh or torus.')
        sys.exit(0)
    if (not str.isdigit(npCU)):
        print('The third argument <npCU> needs to be an integer number.')
        sys.exit(0)
    if (not str.isdigit(dimx)):
        print('The fourth argument <dimx> needs to be an integer number.')
        sys.exit(0)
    if (not str.isdigit(dimy)):
        print('The fifth argument <dimy> needs to be an integer number.')
        sys.exit(0)
    topo = topo.lower()
    npCU = int(npCU)
    dimx = int(dimx)
    dimy = int(dimy)

tstart = 500
tstop = 1500
sname = 'spike_recorder'
sd_names, node_ids, data = __load_spike_times(pname, sname, tstart, tstop)
pop_sizes = []
for n in range(0, node_ids.shape[0]):
    pop_sizes.append(node_ids[n][1] - node_ids[n][0] + 1)
senders = {}
for k in data:
    senders[k] = data[k]['sender'].tolist()

fin = os.path.join(pname, 'NEST_MicroCirc_Connections.yaml')
with open(fin, 'rt') as fi:
    yf = yaml.safe_load(fi)

receivers = defaultdict(list)
for k in senders:
    for s in senders[k]:
        if s in yf[k]:
            receivers[k].append(yf[k][s])
    # Note: Neurons are also connected to spike recorders
    #       These connections need to be filtered out, when the
    #       neuron to node mapping is performed
    sd_ids = [int(x.split('-')[-1]) for x in sd_names]
    receivers[k] = [filter(lambda y: y not in sd_ids, x) for x in receivers[k]]

llength = []
for k in senders:
    for i, s in enumerate(senders[k]):
        # According to the way in which the 'senders' and 'receivers' dictionaries
        # are composed, a source neuron can always be associated with all its
        # receiving neurons.
        # Note that for multicast (MC) only the maximum routing paths are retained.
        ns = int(__get_node_ID_4_neuron(s, npCU, node_ids, pop_sizes))
        nsx = ns % dimx
        nsy = ns // dimx
        nrs = [int(__get_node_ID_4_neuron(x, npCU, node_ids, pop_sizes)) for x in receivers[k][i]]
        nrsx = [ r % dimx for r in nrs]
        nrsy = [ r // dimx for r in nrs]
        if (topo == "mesh"):
            llocal = list(map(lambda xr, yr: abs(xr - nsx) + abs(yr - nsy), nrsx, nrsy))
        else: # Torus
            llocal = list(map(lambda xr, yr: min(abs(xr - nsx), dimx - abs(xr - nsx)) +
                                             min(abs(yr - nsy), dimy - abs(yr - nsy)), nrsx, nrsy))
        llength.append(max(llocal))

lhisto = defaultdict(int)
for x in llength:
    lhisto[x] += 1
lrange = range(0, int(max(lhisto.keys())) + 1)

with open('LinkLengthHisto' + topo[0].upper() + topo[1:] + 'MC.csv', 'wt') as fo:
    fo.write('# Maximum routing paths lengths for the MC case in a ' + topo + '\n')
    for l in lrange:
        if l in lhisto:
            fo.write('{:d} {:d}\n'.format(l, lhisto[l]))
        else:
            fo.write('{:d} {:d}\n'.format(l, 0))
